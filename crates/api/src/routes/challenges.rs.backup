use axum::{
    extract::{Path, Query, State},
    http::StatusCode,
    response::Json,
    routing::{get, post},
    Router,
};
use serde::Deserialize;
use serde_json::Value as JsonValue;
use sqlx::Row;
use uuid::Uuid;

use crate::state::AppState;
use platform_api_models::{
    ChallengeDetailResponse, ChallengeListResponse, ChallengeMetadata, ChallengeStatus,
    ChallengeVisibility, CreateChallengeRequest, Hotkey, Id, UpdateChallengeRequest,
};
use tracing::debug;

/// Create challenges router
pub fn create_router() -> Router<AppState> {
    Router::new()
        .route("/challenges", get(list_challenges).post(create_challenge))
        .route("/challenges/active", get(get_active_challenges))
        .route("/challenges/specs", get(get_challenge_specs))
        .route("/challenges/public", get(list_challenges_public))
        .route("/challenges/debug", get(debug_challenges))
        .route(
            "/challenges/:id",
            get(get_challenge)
                .put(update_challenge)
                .delete(delete_challenge),
        )
        .route("/challenges/:id/public", get(get_challenge_public))
        .route("/challenges/:id/emissions", get(get_challenge_emissions))
        .route("/challenges/:id/jobs", get(get_challenge_jobs))
        .route(
            "/challenges/:compose_hash/env-vars",
            post(store_challenge_env_vars),
        )
}

/// List challenges with pagination
pub async fn list_challenges(
    State(state): State<AppState>,
    Query(params): Query<ListChallengesParams>,
) -> Result<Json<ChallengeListResponse>, StatusCode> {
    debug!("Starting challenge list query");

    let pool = state.database_pool.as_ref().ok_or_else(|| {
        tracing::error!("Database pool not available");
        StatusCode::SERVICE_UNAVAILABLE
    })?;

    let page = params.page.unwrap_or(1);
    let per_page = params.per_page.unwrap_or(20);
    let offset = (page - 1) * per_page;

    debug!(
        "Query parameters: page={}, per_page={}, offset={}",
        page, per_page, offset
    );

    // First, get total count
    debug!("Executing COUNT query");
    let total: i64 = sqlx::query_scalar("SELECT COUNT(*) FROM challenges")
        .persistent(false)
        .fetch_one(pool.as_ref())
        .await
        .map_err(|e| {
            tracing::error!("Failed to count challenges: {}", e);
            tracing::error!("   Error details: {:?}", e);
            StatusCode::INTERNAL_SERVER_ERROR
        })?;

    debug!("Total challenges in database: {}", total);

    // Query challenges from database with pagination
    #[derive(sqlx::FromRow)]
    struct ChallengeRow {
        id: uuid::Uuid,
        name: String,
        compose_hash: String,
        compose_yaml: String,
        version: String,
        images: Vec<String>,
        resources: JsonValue,
        ports: JsonValue,
        env: JsonValue,
        emission_share: f64,
        mechanism_id: i16,
        weight: Option<f64>,
        description: Option<String>,
        mermaid_chart: Option<String>,
        github_repo: Option<String>,
        dstack_image: Option<String>,
        created_at: chrono::DateTime<chrono::Utc>,
        updated_at: chrono::DateTime<chrono::Utc>,
    }

    let query_sql = r#"
        SELECT 
            id, name, compose_hash, compose_yaml, version, images,
            resources, ports, env, emission_share, mechanism_id, weight,
            description, mermaid_chart, github_repo, dstack_image, 
            created_at, updated_at
        FROM challenges
        ORDER BY created_at DESC
        LIMIT $1 OFFSET $2
        "#;

    debug!(
        "Executing SELECT query with LIMIT={}, OFFSET={}",
        per_page, offset
    );
    tracing::debug!("   SQL: {}", query_sql);

    let rows = sqlx::query_as::<_, ChallengeRow>(query_sql)
        .persistent(false)
        .bind(per_page as i64)
        .bind(offset as i64)
        .fetch_all(pool.as_ref())
        .await
        .map_err(|e| {
            tracing::error!("Failed to query challenges: {}", e);
            tracing::error!("   Error details: {:?}", e);
            tracing::error!("   SQL query: {}", query_sql);
            tracing::error!("   Parameters: LIMIT={}, OFFSET={}", per_page, offset);
            StatusCode::INTERNAL_SERVER_ERROR
        })?;

    debug!("Query returned {} rows from database", rows.len());

    if rows.is_empty() && total > 0 {
        tracing::warn!(
            "No rows returned but total count is {} - possible pagination issue",
            total
        );
    }

    // Log each challenge found
    for (idx, row) in rows.iter().enumerate() {
        tracing::info!(
            "   Challenge {}: id={}, name={}, compose_hash={}, version={}",
            idx + 1,
            row.id,
            row.name,
            row.compose_hash,
            row.version
        );
    }

    // Convert ChallengeRow to ChallengeMetadata
    let challenges: Vec<ChallengeMetadata> = rows
        .into_iter()
        .map(|row| ChallengeMetadata {
            id: Id::from(row.id),
            name: row.name.clone(),
            description: row.description.unwrap_or_default(),
            version: row.version.clone(),
            visibility: ChallengeVisibility::Public, // Default to Public
            status: ChallengeStatus::Active, // All challenges in database are considered active
            owner: Hotkey::from("platform"), // Default owner
            created_at: row.created_at,
            updated_at: row.updated_at,
            tags: vec![], // No tags for now
        })
        .collect();

    debug!("Converted {} rows to ChallengeMetadata", challenges.len());

    // Apply status filter if provided (in-memory filter since status is not in DB yet)
    let filtered_challenges: Vec<ChallengeMetadata> = if let Some(status_filter) = &params.status {
        debug!("Applying status filter: {}", status_filter);
        let filtered: Vec<ChallengeMetadata> = challenges
            .into_iter()
            .filter(|c| match status_filter.as_str() {
                "Active" => matches!(c.status, ChallengeStatus::Active),
                "Draft" => matches!(c.status, ChallengeStatus::Draft),
                "Paused" => matches!(c.status, ChallengeStatus::Paused),
                "Archived" => matches!(c.status, ChallengeStatus::Archived),
                _ => true,
            })
            .collect();
        debug!("After status filter: {} challenges", filtered.len());
        filtered
    } else {
        challenges
    };

    let response = ChallengeListResponse {
        challenges: filtered_challenges.clone(),
        total: total as u64,
        page,
        per_page,
    };

    debug!(
        "Returning {} challenges (page {}, per_page {}, total {})",
        response.challenges.len(),
        page,
        per_page,
        total
    );

    if response.challenges.is_empty() && total == 0 {
        tracing::warn!("No challenges found in database! Table 'challenges' is empty.");
        tracing::warn!(
            "   Hint: Check if migrations have been applied and if data has been inserted."
        );
    }

    Ok(Json(response))
}

/// Get challenge details
pub async fn get_challenge(
    State(state): State<AppState>,
    Path(id): Path<Uuid>,
) -> Result<Json<ChallengeDetailResponse>, StatusCode> {
    let pool = state
        .database_pool
        .as_ref()
        .ok_or(StatusCode::SERVICE_UNAVAILABLE)?;

    #[derive(sqlx::FromRow)]
    struct ChallengeRow {
        id: uuid::Uuid,
        name: String,
        compose_hash: String,
        compose_yaml: String,
        version: String,
        images: Vec<String>,
        resources: JsonValue,
        ports: JsonValue,
        env: JsonValue,
        emission_share: f64,
        mechanism_id: i16,
        weight: Option<f64>,
        description: Option<String>,
        mermaid_chart: Option<String>,
        github_repo: Option<String>,
        dstack_image: Option<String>,
        created_at: chrono::DateTime<chrono::Utc>,
        updated_at: chrono::DateTime<chrono::Utc>,
    }

    let row = sqlx::query_as::<_, ChallengeRow>(
        r#"
        SELECT 
            id, name, compose_hash, compose_yaml, version, images,
            resources, ports, env, emission_share, mechanism_id, weight,
            description, mermaid_chart, github_repo, dstack_image,
            created_at, updated_at
        FROM challenges
        WHERE id = $1
        "#,
    )
    .persistent(false)
    .bind(id)
    .fetch_optional(pool.as_ref())
    .await
    .map_err(|e| {
        tracing::error!("Failed to query challenge: {}", e);
        StatusCode::INTERNAL_SERVER_ERROR
    })?;

    if let Some(row) = row {
        let metadata = ChallengeMetadata {
            id: Id::from(row.id),
            name: row.name,
            description: row.description.unwrap_or_default(),
            version: row.version,
            visibility: ChallengeVisibility::Public,
            status: ChallengeStatus::Active,
            owner: Hotkey::from("platform"),
            created_at: row.created_at,
            updated_at: row.updated_at,
            tags: vec![],
        };

        let response = ChallengeDetailResponse {
            metadata,
            harness: None,
            datasets: vec![],
            emissions: None,
        };

        Ok(Json(response))
    } else {
        Err(StatusCode::NOT_FOUND)
    }
}

/// Create new challenge
pub async fn create_challenge(
    State(state): State<AppState>,
    Json(request): Json<CreateChallengeRequest>,
) -> Result<Json<ChallengeMetadata>, StatusCode> {
    let challenge = state
        .builder
        .create_challenge(request)
        .await
        .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;

    Ok(Json(challenge))
}

/// Update challenge
pub async fn update_challenge(
    State(state): State<AppState>,
    Path(id): Path<Uuid>,
    Json(request): Json<UpdateChallengeRequest>,
) -> Result<Json<ChallengeMetadata>, StatusCode> {
    let challenge = state
        .builder
        .update_challenge(id, request)
        .await
        .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;

    Ok(Json(challenge))
}

/// Delete challenge
pub async fn delete_challenge(
    State(state): State<AppState>,
    Path(id): Path<Uuid>,
) -> Result<StatusCode, StatusCode> {
    state
        .builder
        .delete_challenge(id)
        .await
        .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;

    Ok(StatusCode::NO_CONTENT)
}

/// Get challenge emissions
pub async fn get_challenge_emissions(
    State(state): State<AppState>,
    Path(id): Path<Uuid>,
) -> Result<Json<platform_api_models::EmissionsSchedule>, StatusCode> {
    let emissions = state
        .storage
        .get_challenge_emissions(id)
        .await
        .map_err(|_| StatusCode::NOT_FOUND)?;

    Ok(Json(emissions))
}

/// Get active challenges only
pub async fn get_active_challenges(
    State(state): State<AppState>,
) -> Result<Json<serde_json::Value>, StatusCode> {
    let pool = state
        .database_pool
        .as_ref()
        .ok_or(StatusCode::SERVICE_UNAVAILABLE)?;

    #[derive(sqlx::FromRow)]
    struct ChallengeRow {
        id: uuid::Uuid,
        name: String,
        compose_hash: String,
        github_repo: Option<String>,
        mechanism_id: i16,
        emission_share: f64,
        resources: JsonValue,
    }

    let rows = sqlx::query_as::<_, ChallengeRow>(
        r#"
        SELECT id, name, compose_hash, github_repo, mechanism_id, emission_share, resources
        FROM challenges
        ORDER BY created_at DESC
        "#,
    )
    .persistent(false)
    .fetch_all(pool.as_ref())
    .await
    .map_err(|e| {
        tracing::error!("Failed to query active challenges: {}", e);
        StatusCode::INTERNAL_SERVER_ERROR
    })?;

    tracing::info!(
        "get_active_challenges: returning {} challenges from database",
        rows.len()
    );

    Ok(Json(serde_json::json!({
        "challenges": rows.iter().map(|row| serde_json::json!({
            "id": row.id.to_string(),
            "name": row.name.clone(),
            "status": "Active", // All challenges in database are considered active
            "github_repo": row.github_repo.clone().unwrap_or_default(),
            "github_commit": "", // Not stored in DB, derived from compose_hash
            "resource_requirements": row.resources.clone(),
            "compose_hash": row.compose_hash.clone(),
            "mechanism_id": row.mechanism_id as u8,
            "emission_share": row.emission_share,
        })).collect::<Vec<_>>()
    })))
}

/// Get full challenge specs (for validator polling)
pub async fn get_challenge_specs(
    State(state): State<AppState>,
) -> Result<Json<serde_json::Value>, StatusCode> {
    tracing::info!("get_challenge_specs: retrieving full challenge specifications");

    // Use the same list_challenges method as WebSocket
    let challenges = state.list_challenges().await;

    tracing::info!(
        "get_challenge_specs: returning {} challenge specs",
        challenges.len()
    );

    Ok(Json(serde_json::json!({
        "type": "challenges:list",
        "challenges": challenges
    })))
}

/// Debug endpoint to diagnose challenges table state
pub async fn debug_challenges(
    State(state): State<AppState>,
) -> Result<Json<serde_json::Value>, StatusCode> {
    let pool = state
        .database_pool
        .as_ref()
        .ok_or(StatusCode::SERVICE_UNAVAILABLE)?;

    debug!("Starting diagnostic query");

    // Get total count
    let total_count: i64 = sqlx::query_scalar("SELECT COUNT(*) FROM challenges")
        .persistent(false)
        .fetch_one(pool.as_ref())
        .await
        .map_err(|e| {
            tracing::error!("Failed to count challenges: {}", e);
            StatusCode::INTERNAL_SERVER_ERROR
        })?;

    // Get table columns and types
    #[derive(sqlx::FromRow)]
    struct ColumnInfo {
        column_name: String,
        data_type: String,
        is_nullable: String,
    }

    let columns: Vec<ColumnInfo> = sqlx::query_as::<_, ColumnInfo>(
        r#"
        SELECT column_name, data_type, is_nullable
        FROM information_schema.columns
        WHERE table_schema = 'public' AND table_name = 'challenges'
        ORDER BY ordinal_position
        "#,
    )
    .persistent(false)
    .fetch_all(pool.as_ref())
    .await
    .map_err(|e| {
        tracing::error!("Failed to get column info: {}", e);
        StatusCode::INTERNAL_SERVER_ERROR
    })?;

    // Get first challenge if exists
    let first_challenge: Option<serde_json::Value> = if total_count > 0 {
        let row = sqlx::query(
            r#"
            SELECT id, name, compose_hash, version, mechanism_id, created_at
            FROM challenges
            ORDER BY created_at DESC
            LIMIT 1
            "#,
        )
        .persistent(false)
        .fetch_optional(pool.as_ref())
        .await
        .map_err(|e| {
            tracing::error!("Failed to get first challenge: {}", e);
            StatusCode::INTERNAL_SERVER_ERROR
        })?;

        row.map(|row| serde_json::json!({
                "id": row.get::<uuid::Uuid, _>("id"),
                "name": row.get::<String, _>("name"),
                "compose_hash": row.get::<String, _>("compose_hash"),
                "version": row.get::<String, _>("version"),
                "mechanism_id": row.get::<i16, _>("mechanism_id"),
                "created_at": row.get::<chrono::DateTime<chrono::Utc>, _>("created_at"),
            }))
    } else {
        None
    };

    // Check if mechanism_id is SMALLINT or VARCHAR
    let mechanism_id_type: Option<String> = columns
        .iter()
        .find(|c| c.column_name == "mechanism_id")
        .map(|c| c.data_type.clone());

    let response = serde_json::json!({
        "database_connected": true,
        "table_exists": true,
        "total_challenges": total_count,
        "table_columns": columns.iter().map(|c| serde_json::json!({
            "name": c.column_name,
            "type": c.data_type,
            "nullable": c.is_nullable == "YES"
        })).collect::<Vec<_>>(),
        "mechanism_id_type": mechanism_id_type,
        "first_challenge": first_challenge,
        "diagnosis": if total_count == 0 {
            "Table is empty - no challenges found. Check if migrations have been applied and if data has been inserted."
        } else if mechanism_id_type.as_deref() == Some("character varying") {
            "WARNING: mechanism_id is VARCHAR but should be SMALLINT. Migration 004 may not have been applied."
        } else {
            "Table structure looks correct"
        }
    });

    tracing::info!("Diagnostic complete: {} challenges found", total_count);

    Ok(Json(response))
}

/// Query parameters for listing challenges
#[derive(Debug, Deserialize)]
pub struct ListChallengesParams {
    pub page: Option<u32>,
    pub per_page: Option<u32>,
    pub status: Option<String>,
    pub visibility: Option<String>,
}

/// Get all jobs for a challenge with results
pub async fn get_challenge_jobs(
    State(state): State<AppState>,
    Path(id): Path<Uuid>,
    Query(params): Query<ChallengeJobsParams>,
) -> Result<Json<JsonValue>, StatusCode> {
    // Get jobs for this challenge using scheduler (which uses PostgreSQL)
    let page = params.page.unwrap_or(1);
    let per_page = params.per_page.unwrap_or(20);

    let jobs = state
        .scheduler
        .list_jobs(page, per_page, params.status, Some(id))
        .await
        .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;

    // For each job, get test results count
    let jobs_with_results: Vec<JsonValue> = jobs
        .jobs
        .iter()
        .map(|job| {
            // Count test results for this job (we'll fetch details separately if needed)
            serde_json::json!({
                "job": job,
                "has_test_results": false, // Will be populated if test_results detail is requested
            })
        })
        .collect();

    Ok(Json(serde_json::json!({
        "challenge_id": id,
        "jobs": jobs_with_results,
        "total": jobs.total,
        "page": jobs.page,
        "per_page": jobs.per_page,
    })))
}

/// Query parameters for challenge jobs
#[derive(Debug, Deserialize)]
pub struct ChallengeJobsParams {
    pub page: Option<u32>,
    pub per_page: Option<u32>,
    pub status: Option<String>,
    pub include_test_results: Option<bool>,
}

/// Request body for storing challenge environment variables
#[derive(Debug, Deserialize)]
pub struct StoreChallengeEnvVarsRequest {
    pub env_vars: std::collections::HashMap<String, String>,
}

/// Store challenge environment variables (encrypted)
pub async fn store_challenge_env_vars(
    State(state): State<AppState>,
    Path(compose_hash): Path<String>,
    Json(request): Json<StoreChallengeEnvVarsRequest>,
) -> Result<Json<serde_json::Value>, StatusCode> {
    tracing::info!(
        compose_hash = %compose_hash,
        count = request.env_vars.len(),
        "Storing environment variables for challenge"
    );

    // Store each environment variable
    for (key, value) in request.env_vars.iter() {
        if let Err(e) = state
            .store_challenge_env_var(&compose_hash, key, value)
            .await
        {
            tracing::error!(
                compose_hash = %compose_hash,
                key = %key,
                error = %e,
                "Failed to store environment variable"
            );
            return Err(StatusCode::INTERNAL_SERVER_ERROR);
        }
    }

    tracing::info!(
        compose_hash = %compose_hash,
        count = request.env_vars.len(),
        "Successfully stored environment variables for challenge"
    );

    Ok(Json(serde_json::json!({
        "compose_hash": compose_hash,
        "stored_count": request.env_vars.len(),
        "message": "Environment variables stored successfully"
    })))
}

/// Public challenge response structure
#[derive(Debug, serde::Serialize, serde::Deserialize)]
pub struct PublicChallengeResponse {
    pub id: String,
    pub name: String,
    pub status: String,
    pub description: Option<String>,
    pub difficulty: Option<String>,
    pub mechanism_id: i16,
    pub emission_share: f64,
    pub github_repo: Option<String>,
    pub created_at: String,
    pub updated_at: String,
    pub stats: ChallengeStats,
}

#[derive(Debug, serde::Serialize, serde::Deserialize)]
pub struct ChallengeStats {
    pub participant_count: usize,
    pub jobs_processed: usize,
    pub success_rate: f64,
    pub pool_size_tao: f64,
}

#[derive(Debug, serde::Serialize, serde::Deserialize)]
pub struct PublicChallengeListResponse {
    pub challenges: Vec<PublicChallengeResponse>,
    pub total: usize,
}

/// List public challenges (read-only, active challenges only)
pub async fn list_challenges_public(
    State(state): State<AppState>,
) -> Result<Json<PublicChallengeListResponse>, StatusCode> {
    let pool = state.database_pool.as_ref().ok_or_else(|| {
        tracing::error!("Database pool not available");
        StatusCode::SERVICE_UNAVAILABLE
    })?;

    #[derive(sqlx::FromRow)]
    struct ChallengeRow {
        id: uuid::Uuid,
        name: String,
        mechanism_id: i16,
        emission_share: f64,
        description: Option<String>,
        github_repo: Option<String>,
        created_at: chrono::DateTime<chrono::Utc>,
        updated_at: chrono::DateTime<chrono::Utc>,
    }

    // Get active challenges (those with recent jobs)
    let challenges = sqlx::query_as::<_, ChallengeRow>(
        r#"
        SELECT DISTINCT
            c.id, c.name, c.mechanism_id, c.emission_share, c.description, c.github_repo,
            c.created_at, c.updated_at
        FROM challenges c
        INNER JOIN jobs j ON j.challenge_id = c.id
        WHERE j.created_at > NOW() - INTERVAL '30 days'
        ORDER BY c.created_at DESC
        "#,
    )
    .persistent(false)
    .fetch_all(pool.as_ref())
    .await
    .map_err(|e| {
        tracing::error!("Failed to query public challenges: {}", e);
        StatusCode::INTERNAL_SERVER_ERROR
    })?;

    let mut public_challenges = Vec::new();

    for challenge in challenges {
        // Get stats for this challenge
        let participant_count: i64 = sqlx::query_scalar(
            r#"
            SELECT COUNT(DISTINCT miner_hotkey) 
            FROM jobs 
            WHERE challenge_id = $1
            "#,
        )
        .bind(challenge.id)
        .persistent(false)
        .fetch_one(pool.as_ref())
        .await
        .unwrap_or(0);

        let jobs_processed: i64 = sqlx::query_scalar(
            r#"
            SELECT COUNT(*) 
            FROM jobs 
            WHERE challenge_id = $1
            "#,
        )
        .bind(challenge.id)
        .persistent(false)
        .fetch_one(pool.as_ref())
        .await
        .unwrap_or(0);

        let completed_jobs: i64 = sqlx::query_scalar(
            r#"
            SELECT COUNT(*) 
            FROM jobs 
            WHERE challenge_id = $1 AND status = 'completed'
            "#,
        )
        .bind(challenge.id)
        .persistent(false)
        .fetch_one(pool.as_ref())
        .await
        .unwrap_or(0);

        let success_rate = if jobs_processed > 0 {
            (completed_jobs as f64 / jobs_processed as f64) * 100.0
        } else {
            0.0
        };

        // Calculate pool size (simplified - would need actual emissions data)
        let pool_size_tao = challenge.emission_share * 1000.0; // Assuming 1000 TAO/day total

        // Determine difficulty
        let difficulty = if challenge.emission_share > 0.5 {
            Some("Expert".to_string())
        } else if challenge.emission_share > 0.3 {
            Some("Hard".to_string())
        } else if challenge.emission_share > 0.1 {
            Some("Medium".to_string())
        } else {
            Some("Easy".to_string())
        };

        public_challenges.push(PublicChallengeResponse {
            id: challenge.id.to_string(),
            name: challenge.name,
            status: "live".to_string(),
            description: challenge.description,
            difficulty,
            mechanism_id: challenge.mechanism_id,
            emission_share: challenge.emission_share,
            github_repo: challenge.github_repo,
            created_at: challenge.created_at.to_rfc3339(),
            updated_at: challenge.updated_at.to_rfc3339(),
            stats: ChallengeStats {
                participant_count: participant_count as usize,
                jobs_processed: jobs_processed as usize,
                success_rate,
                pool_size_tao,
            },
        });
    }

    Ok(Json(PublicChallengeListResponse {
        total: public_challenges.len(),
        challenges: public_challenges,
    }))
}

/// Get public challenge details (read-only)
pub async fn get_challenge_public(
    State(state): State<AppState>,
    Path(id): Path<Uuid>,
) -> Result<Json<PublicChallengeResponse>, StatusCode> {
    let pool = state.database_pool.as_ref().ok_or_else(|| {
        tracing::error!("Database pool not available");
        StatusCode::SERVICE_UNAVAILABLE
    })?;

    #[derive(sqlx::FromRow)]
    struct ChallengeRow {
        id: uuid::Uuid,
        name: String,
        mechanism_id: i16,
        emission_share: f64,
        description: Option<String>,
        github_repo: Option<String>,
        created_at: chrono::DateTime<chrono::Utc>,
        updated_at: chrono::DateTime<chrono::Utc>,
    }

    let challenge = sqlx::query_as::<_, ChallengeRow>(
        r#"
        SELECT 
            id, name, mechanism_id, emission_share, description, github_repo,
            created_at, updated_at
        FROM challenges
        WHERE id = $1
        "#,
    )
    .bind(id)
    .persistent(false)
    .fetch_optional(pool.as_ref())
    .await
    .map_err(|e| {
        tracing::error!("Failed to query challenge: {}", e);
        StatusCode::INTERNAL_SERVER_ERROR
    })?;

    let challenge = challenge.ok_or(StatusCode::NOT_FOUND)?;

    // Get stats
    let participant_count: i64 = sqlx::query_scalar(
        r#"
        SELECT COUNT(DISTINCT miner_hotkey) 
        FROM jobs 
        WHERE challenge_id = $1
        "#,
    )
    .bind(challenge.id)
    .persistent(false)
    .fetch_one(pool.as_ref())
    .await
    .unwrap_or(0);

    let jobs_processed: i64 = sqlx::query_scalar(
        r#"
        SELECT COUNT(*) 
        FROM jobs 
        WHERE challenge_id = $1
        "#,
    )
    .bind(challenge.id)
    .persistent(false)
    .fetch_one(pool.as_ref())
    .await
    .unwrap_or(0);

    let completed_jobs: i64 = sqlx::query_scalar(
        r#"
        SELECT COUNT(*) 
        FROM jobs 
        WHERE challenge_id = $1 AND status = 'completed'
        "#,
    )
    .bind(challenge.id)
    .persistent(false)
    .fetch_one(pool.as_ref())
    .await
    .unwrap_or(0);

    let success_rate = if jobs_processed > 0 {
        (completed_jobs as f64 / jobs_processed as f64) * 100.0
    } else {
        0.0
    };

    let pool_size_tao = challenge.emission_share * 1000.0; // Simplified calculation

    let difficulty = if challenge.emission_share > 0.5 {
        Some("Expert".to_string())
    } else if challenge.emission_share > 0.3 {
        Some("Hard".to_string())
    } else if challenge.emission_share > 0.1 {
        Some("Medium".to_string())
    } else {
        Some("Easy".to_string())
    };

    Ok(Json(PublicChallengeResponse {
        id: challenge.id.to_string(),
        name: challenge.name,
        status: "live".to_string(),
        description: challenge.description,
        difficulty,
        mechanism_id: challenge.mechanism_id,
        emission_share: challenge.emission_share,
        github_repo: challenge.github_repo,
        created_at: challenge.created_at.to_rfc3339(),
        updated_at: challenge.updated_at.to_rfc3339(),
        stats: ChallengeStats {
            participant_count: participant_count as usize,
            jobs_processed: jobs_processed as usize,
            success_rate,
            pool_size_tao,
        },
    }))
}
